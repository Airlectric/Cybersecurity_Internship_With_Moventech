{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7670451,"sourceType":"datasetVersion","datasetId":4473813}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Bidirectional, LSTM, Dense, Concatenate, Input\nfrom keras.models import Model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('/kaggle/input/network-traffic-for-dos-detection/dataset.csv')\n\n# Print columns of the DataFrame\nprint(\"Columns after loading dataset:\")\nprint(df.columns)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T22:55:19.208084Z","iopub.execute_input":"2024-02-25T22:55:19.208528Z","iopub.status.idle":"2024-02-25T22:55:19.817665Z","shell.execute_reply.started":"2024-02-25T22:55:19.208492Z","shell.execute_reply":"2024-02-25T22:55:19.816289Z"},"trusted":true},"execution_count":139,"outputs":[{"name":"stdout","text":"Columns after loading dataset:\nIndex(['Id', 'IP', 'bot', 'FunctionId', 'functionTrigger', 'timestamp',\n       'SubmitTime', 'RTT', 'InvocationDelay', 'ResponseDelay',\n       'FunctionDuration', 'ActiveFunctionsAtRequest',\n       'ActiveFunctionsAtResponse', 'maxcpu', 'avgcpu', 'p95maxcpu',\n       'vmcategory', 'vmcorecountbucket', 'vmmemorybucket'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"def calculate_entropy(feature_values):\n    # Convert float64 data to integer by rounding\n    feature_values = np.round(feature_values).astype(int)\n    \n    # Count occurrences of each unique value in the feature\n    value_counts = np.bincount(feature_values)\n    \n    # Calculate probability of each unique value\n    probabilities = value_counts / len(feature_values)\n    \n    # Calculate entropy\n    entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))  # Adding a small value to avoid log(0)\n    \n    return entropy","metadata":{"execution":{"iopub.status.busy":"2024-02-25T22:55:19.819579Z","iopub.execute_input":"2024-02-25T22:55:19.819942Z","iopub.status.idle":"2024-02-25T22:55:19.827039Z","shell.execute_reply.started":"2024-02-25T22:55:19.819909Z","shell.execute_reply":"2024-02-25T22:55:19.825290Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"# Function to prepare dataset and calculate entropy\ndef prepare_dataset(df):\n    # Select relevant features\n    selected_features = ['RTT', 'InvocationDelay', 'ResponseDelay', 'FunctionDuration', 'ActiveFunctionsAtRequest', \n                         'ActiveFunctionsAtResponse', 'maxcpu', 'avgcpu', 'p95maxcpu', 'vmcorecountbucket', 'vmmemorybucket']\n    \n    # Normalize selected features if necessary\n    scaler = MinMaxScaler()\n    df[selected_features] = scaler.fit_transform(df[selected_features])\n    \n    # Calculate entropy for each data instance\n    for feature in selected_features:\n        df[feature + '_entropy'] = df.groupby('IP')[feature].transform(lambda x: calculate_entropy(x.values))\n    \n    # Print columns after adding entropy columns\n    print(\"Columns after adding entropy columns:\")\n    print(df.columns)\n    \n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-02-25T22:55:19.828966Z","iopub.execute_input":"2024-02-25T22:55:19.829449Z","iopub.status.idle":"2024-02-25T22:55:19.843440Z","shell.execute_reply.started":"2024-02-25T22:55:19.829407Z","shell.execute_reply":"2024-02-25T22:55:19.842199Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"# Function to prepare data for model training\ndef prepare_data_for_model(df):\n    # Convert categorical variables to numerical labels if necessary\n    label_encoder = LabelEncoder()\n    df['vmcategory'] = label_encoder.fit_transform(df['vmcategory'])\n    \n    # Select features and target\n    selected_features = ['RTT_entropy', 'InvocationDelay_entropy', 'ResponseDelay_entropy', 'FunctionDuration_entropy', \n                         'ActiveFunctionsAtRequest_entropy', 'ActiveFunctionsAtResponse_entropy', 'maxcpu_entropy', \n                         'avgcpu_entropy', 'p95maxcpu_entropy', 'vmcorecountbucket_entropy', 'vmmemorybucket_entropy']\n    X = df[selected_features].values\n    y = df['bot'].values\n    \n    # Reshape data for LSTM input\n    X = X.reshape(X.shape[0], X.shape[1], 1)\n    \n    return X, y","metadata":{"execution":{"iopub.status.busy":"2024-02-25T22:55:20.618581Z","iopub.execute_input":"2024-02-25T22:55:20.619056Z","iopub.status.idle":"2024-02-25T22:55:20.629210Z","shell.execute_reply.started":"2024-02-25T22:55:20.619023Z","shell.execute_reply":"2024-02-25T22:55:20.626034Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"# Print columns of the DataFrame\nprint(\"Columns after loading dataset:\")\nprint(df.columns)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T22:55:20.798724Z","iopub.execute_input":"2024-02-25T22:55:20.799851Z","iopub.status.idle":"2024-02-25T22:55:20.806080Z","shell.execute_reply.started":"2024-02-25T22:55:20.799808Z","shell.execute_reply":"2024-02-25T22:55:20.804937Z"},"trusted":true},"execution_count":143,"outputs":[{"name":"stdout","text":"Columns after loading dataset:\nIndex(['Id', 'IP', 'bot', 'FunctionId', 'functionTrigger', 'timestamp',\n       'SubmitTime', 'RTT', 'InvocationDelay', 'ResponseDelay',\n       'FunctionDuration', 'ActiveFunctionsAtRequest',\n       'ActiveFunctionsAtResponse', 'maxcpu', 'avgcpu', 'p95maxcpu',\n       'vmcategory', 'vmcorecountbucket', 'vmmemorybucket'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to build Bi-LSTM model\ndef build_model(input_shape):\n    model = Sequential()\n    model.add(Bidirectional(LSTM(units=64, return_sequences=True), input_shape=input_shape))\n    model.add(Bidirectional(LSTM(units=32)))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-02-25T22:55:20.880195Z","iopub.execute_input":"2024-02-25T22:55:20.880641Z","iopub.status.idle":"2024-02-25T22:55:20.887239Z","shell.execute_reply.started":"2024-02-25T22:55:20.880586Z","shell.execute_reply":"2024-02-25T22:55:20.886101Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"# Prepare dataset and calculate entropy\ndf = prepare_dataset(df)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T22:55:20.889421Z","iopub.execute_input":"2024-02-25T22:55:20.890649Z","iopub.status.idle":"2024-02-25T22:55:35.167973Z","shell.execute_reply.started":"2024-02-25T22:55:20.890584Z","shell.execute_reply":"2024-02-25T22:55:35.165006Z"},"trusted":true},"execution_count":145,"outputs":[{"name":"stdout","text":"Columns after adding entropy columns:\nIndex(['Id', 'IP', 'bot', 'FunctionId', 'functionTrigger', 'timestamp',\n       'SubmitTime', 'RTT', 'InvocationDelay', 'ResponseDelay',\n       'FunctionDuration', 'ActiveFunctionsAtRequest',\n       'ActiveFunctionsAtResponse', 'maxcpu', 'avgcpu', 'p95maxcpu',\n       'vmcategory', 'vmcorecountbucket', 'vmmemorybucket', 'RTT_entropy',\n       'InvocationDelay_entropy', 'ResponseDelay_entropy',\n       'FunctionDuration_entropy', 'ActiveFunctionsAtRequest_entropy',\n       'ActiveFunctionsAtResponse_entropy', 'maxcpu_entropy', 'avgcpu_entropy',\n       'p95maxcpu_entropy', 'vmcorecountbucket_entropy',\n       'vmmemorybucket_entropy'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\n\nfunction_trigger_mapping = {'notification': 0, 'other_value': 1}\n\ndf['functionTrigger'] = df['functionTrigger'].map(function_trigger_mapping)\n\nnumerical_columns = ['Id', 'bot', 'FunctionId', 'functionTrigger', 'SubmitTime', 'RTT',\n                     'InvocationDelay', 'ResponseDelay', 'FunctionDuration', 'ActiveFunctionsAtRequest',\n                     'ActiveFunctionsAtResponse', 'maxcpu', 'avgcpu', 'p95maxcpu', 'vmcorecountbucket',\n                     'vmmemorybucket']\n\n# Impute NaN values with a specific value, such as 0\nimputer = SimpleImputer(strategy='constant', fill_value=0)\ndf[numerical_columns] = imputer.fit_transform(df[numerical_columns])\n\nscaler = MinMaxScaler()\nX_scaled = scaler.fit_transform(df[numerical_columns])","metadata":{"execution":{"iopub.status.busy":"2024-02-25T22:55:35.170148Z","iopub.execute_input":"2024-02-25T22:55:35.170486Z","iopub.status.idle":"2024-02-25T22:55:35.641364Z","shell.execute_reply.started":"2024-02-25T22:55:35.170456Z","shell.execute_reply":"2024-02-25T22:55:35.640113Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"# Prepare data for model training\n# Split the dataset into training, validation, and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T22:55:35.643150Z","iopub.execute_input":"2024-02-25T22:55:35.643528Z","iopub.status.idle":"2024-02-25T22:55:35.720728Z","shell.execute_reply.started":"2024-02-25T22:55:35.643496Z","shell.execute_reply":"2024-02-25T22:55:35.719566Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"# Reshape the input data to match the LSTM input shape\ntimesteps = 1  # Assuming each sample represents a single timestep\nnum_features = X_scaled.shape[1]  # Use the scaled dataset for reshaping\nX_train = X_train.reshape(X_train.shape[0], timesteps, num_features)\nX_val = X_val.reshape(X_val.shape[0], timesteps, num_features)\nX_test = X_test.reshape(X_test.shape[0], timesteps, num_features)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T22:55:35.724095Z","iopub.execute_input":"2024-02-25T22:55:35.724575Z","iopub.status.idle":"2024-02-25T22:55:35.731447Z","shell.execute_reply.started":"2024-02-25T22:55:35.724533Z","shell.execute_reply":"2024-02-25T22:55:35.730180Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"# Train the model\nmodel.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_split=0.2)\n\n# Make predictions on the test set\npredictions = model.predict(X_test_reshaped)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-25T22:55:35.733458Z","iopub.execute_input":"2024-02-25T22:55:35.733871Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n 300/3742 [=>............................] - ETA: 10:57 - loss: 0.6110 - accuracy: 0.7059","output_type":"stream"}]},{"cell_type":"code","source":"# Make predictions on the test set\npredictions = model.predict(X_test_scaled)\nbinary_predictions = (predictions > 0.5).astype(int)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, binary_predictions)\nprint(\"Accuracy:\", accuracy)\n\nprint(\"Classification Report:\")\nprint(classification_report(y_test, binary_predictions))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}